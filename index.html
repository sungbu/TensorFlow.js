<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>1.快速上手</title>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@2.0.0/dist/tf.min.js"></script>
    <!-- 图标库 -->
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-vis"></script>
</head>
<body>
    <script>
        //创建模型
        function createModel() {
            //创建一个顺序模型，它是一个由一系列层组成的线性堆栈。
            const model = tf.sequential();

            //创建一个密集层 向模型中添加一个密集层，即全连接层。这个层有一个节点，即输出一个值，同时它接受一个单一的数值作为输入。其中的参数包括：
            model.add(tf.layers.dense({
                units: 1, //点的数量是1，这是线性回归的标准设置。
                useBias: true, //这个层是否包含偏置参数，也就是截距项。默认情况下是true，意味着这个层有一个截距项。
                activation: "linear", //使用线性激活函数。由于这是一个线性回归模型，所以激活函数应该是线性的。
                inputDim: 1 //输入数据的维度是1，这是因为我们只有一个单一的输入变量。
            }));

            const optimizer = tf.train.sgd(0.1);//定义一个随机梯度下降（SGD）优化器，用于更新模型中的权重和偏置参数。学习率是0.1，它控制了每个参数在每个训练步骤中更新的大小。
            //编译模型，指定损失函数。这里使用均方误差（mean squared error）作为损失函数，因为它是一个适合回归问题的标准损失函数。我们的目标是最小化预测值与实际值之间的均方误差。
            model.compile({
                loss: "meanSquaredError",
                optimizer
            })

            return model;
        }

        //训练模型函数
        async function trainModel(model,trainingFeatureTensor,trainingLableTensor) {

            //图表监控学习进度和效率
            const {onEpochEnd,onBatchEnd} = tfvis.show.fitCallbacks(
                {name: "Training Performance"},
                ['loss']
            )

            //函数训练模型，返回一个Promise对象。其中的参数包括
            //trainingFeatureTensor：训练特征张量，用于训练模型。
            //trainingLableTensor：训练标签张量，用于训练模型。
            //epochs: 20：训练轮数，即训练数据集中的所有样本都被用于训练的次数。在这里是20轮，表示数据集将会被训练20次。
            //callbacks: {...}：回调函数对象，这里只有一个回调函数onEpochEnd。
            return model.fit(trainingFeatureTensor,trainingLableTensor,{
                epochs : 20, //多少个纪元
                batchSize: 32, //批大小，即每个批次的样本数。在这里是32个样本，表示每次训练32个样本。
                validationSplit: 0.2, //用训练集的20%的数据作为验证集
                callbacks: {
                    //onEpochEnd: (epach,log) => console.log(`Epochs: ${epach} loss: ${log.loss}`) //epach: 第几纪元年 loss包含了当前epoch的损失函数值和其他度量值。
                    onEpochEnd,
                    //onBatchEnd
                }
            })
        }


        //画图表
        async function plot(pointArray,featureName) {
            tfvis.render.scatterplot(
                //图表名字
                {name: `${featureName} vs House Price`},
                //数据和数据类型名
                {values:[pointArray], series:["original"]},
                //x，y轴名称
                {
                    xLabel: featureName,
                    yLabel: "Price"
                }
            )
        }

        //讲数值归并到0-1区间
        //公式 x = x - min(x) / max(x) - min(x)
        function normalise(tensor) {
            const min = tensor.min();
            const max = tensor.max();

            const normalisedTensor = tensor.sub(min).div(max.sub(min));

            return {
                tensor: normalisedTensor,
                min,
                max
            };
        }

        async function run () {
            //加载csv数据集文件
            const houseScalesDataset = tf.data.csv("http://127.0.0.1:5500/kc_house_data.csv");

            //为图表做准备 x轴为sqft_living  y轴为price
            const pointsDataset = houseScalesDataset.map(record => ({
                x: record.sqft_living,
                y: record.price
            }))
            const points = await pointsDataset.toArray();

            //方便拆分数组 如果数组长度为奇数 85行会报错
            if(points.length % 2 !== 0){
                points.pop();
            }

            //洗牌
            tf.util.shuffle(points);

            plot(points,"Square Feet")


            //创建两个张量Tensor

            //提取一个特征  Feature（inputs）
            const featureValues = points.map(p => p.x);
            const featureTensor = tf.tensor2d(featureValues,[featureValues.length, 1]);

            //提取一个标签   lable（outputs）
            const lableValues = points.map(p => p.y);
            const lableTensor = tf.tensor2d(lableValues,[lableValues.length, 1]);


            //数据归一化 0-1区间
            const normalisedFeature = normalise(featureTensor);
            const normalisedLable = normalise(lableTensor);

            normalisedFeature.tensor.print();
            normalisedLable.tensor.print();

            //将数组按 50% 50% 的比例拆除成两个数组
            const [trainingFeatureTensor,testingFeatureTensor] = tf.split(normalisedFeature.tensor,2);
            const [trainingLableTensor,testingLableTensor] = tf.split(normalisedLable.tensor,2);

            trainingFeatureTensor.print(true);

            const model = createModel();

            //模型的摘要 状态信息（利用控制台显示）
            model.summary();

            //模型的摘要 状态信息 (利用图表显示)
            tfvis.show.modelSummary({name: "model summary"},model);

            //获取第一层layout
            const layer = model.getLayer(undefined,0);

            //layout1的摘要 状态信息 (利用图表显示)
            tfvis.show.layer({name: "layer 1"},layer);

            //训练模型
            const result = await trainModel(model,trainingFeatureTensor,trainingLableTensor);
            console.log(result)

            //训练集
            const trainingLoss = result.history.loss.pop();
            console.log(`Training loss: ${trainingLoss}`); //打印训练集损失率

            //验证集
            const validationLoss = result.history.val_loss.pop();
            console.log(`Validation loss: ${validationLoss}`);//打印验证集损失率

            //测试集
            const lossTensor = model.evaluate(testingFeatureTensor,testingFeatureTensor);
            const loss = await lossTensor.dataSync();
            console.log(`Testing loss: ${loss}`);//打印测试集损失率
        }
        
        run();
    </script>
</body>
</html>